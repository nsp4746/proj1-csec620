{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:36:51.971103Z",
     "start_time": "2024-09-24T01:36:44.577467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Nikhil Patil\n",
    "# CSEC 620\n",
    "# Project 1\n",
    "# This code was sourced from: https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers#numerical_columns\n",
    "# --------------------------------------------\n",
    "# This model is wildly inefficient. It is not reccommended to run. The \"New Model\" is the best version to run. \n",
    "# ----------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import layers\n",
    "\n",
    "file_path = 'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
    "batch_size = 32\n",
    "np.random.seed(3)\n",
    "dataframe = pd.read_csv(file_path)\n",
    "\n",
    "dataframe.columns = dataframe.columns.str.strip()\n",
    "dataframe.columns = dataframe.columns.str.replace(\"/\", \"\", regex=False) # remove any / to prevent any issues when normalizing \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "dataframe['target'] = label_encoder.fit_transform(dataframe['Label'])\n",
    "\n",
    "dataframe['target'] = np.where(dataframe['Label']== 'DDoS', 1, 0)\n",
    "dataframe = dataframe.drop(columns=['Label'])\n",
    "\n",
    "training, validation, test = np.split(dataframe.sample(frac=1), [int(0.8*len(dataframe)), int(0.9*len(dataframe))]) \n",
    "# change dataset size  \n",
    "\n",
    "# print num of traning sizes \n",
    "print(len(training), 'training examples')\n",
    "print(len(validation), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n",
    "\n",
    "\n",
    "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
    "    '''\n",
    "    Name: df_to_dataset\n",
    "    Function: converts pandas dataframe to a dataset to be used by tensorflow\n",
    "    Parameters: df - dataframe, shuffle - boolean to shuffle the dataframe or no, batch_size - the batch size of the dataset\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    labels = df.pop('target')\n",
    "    df = {key: value.to_numpy()[:,tf.newaxis] for key, value in df.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = df_to_dataset(training, batch_size=batch_size)\n",
    "\n",
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "# print('Every feature:', list(train_features.keys()))\n",
    "\n",
    "def get_normalization_layer(name,dataset):\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    normalizer.adapt(feature_ds)\n",
    "    return normalizer\n",
    "\n",
    "\n",
    "train_ds = df_to_dataset(training, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(validation, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, batch_size=batch_size)\n",
    "\n",
    "all_inputs={}\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical Features. These features the best features that were listed for best detecting DDoS attacks. \n",
    "for header in ['Average Packet Size','Flow Duration','Flow IAT Std','Bwd Packet Length Std']:\n",
    "    numeric_col = tf.keras.layers.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs[header] = numeric_col\n",
    "    encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "\n",
    "# Build the model\n",
    "x = layers.Dense(64, activation='relu')(all_features)  # Increase the number of neurons to 64\n",
    "x = layers.Dropout(0.3)(x)  # Add dropout layer to prevent overfitting\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)  # Add another Dense layer with 32 neurons\n",
    "x = layers.Dropout(0.3)(x)  # Another Dropout layer\n",
    "\n",
    "x = layers.Dense(16, activation='relu')(x)  # Add another Dense layer with 16 neurons\n",
    "\n",
    "output = layers.Dense(1, activation='sigmoid')(x)  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "model = tf.keras.Model(inputs=all_inputs, outputs=output)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs=150, validation_data=val_ds)\n",
    "result = model.evaluate(test_ds, return_dict=True)\n",
    "print(result)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "a51cf67a93379d1b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ac27405b49e39ee6"
  },
  {
   "cell_type": "code",
   "id": "51850922-d932-4e24-b58a-e6a6fa7b763a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:37:43.600507Z",
     "start_time": "2024-09-24T01:36:52.012495Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 51.527567625045776 seconds\n",
      "Validation Accuracy: 1.0\n",
      "Test Accuracy: 0.9998228128460687\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9661\n",
      "           1       1.00      1.00      1.00     12914\n",
      "\n",
      "    accuracy                           1.00     22575\n",
      "   macro avg       1.00      1.00      1.00     22575\n",
      "weighted avg       1.00      1.00      1.00     22575\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
